{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the basic data science lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# import display module\n",
    "from IPython.display import display\n",
    "#import stratify kfold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import svc,knn    \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "# nlp \n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "import re\n",
    "import gensim\n",
    "# https://github.com/alexandres/lexvec#pre-trained-vectors\n",
    "# parameter tuning\n",
    "import optuna\n",
    "#import typing\n",
    "from typing import List, Dict, Tuple, Set, Union, Optional, Callable, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 2) (2400, 1) (600, 2) (600, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  website                                               text\n",
       "0  amazon  Oh and I forgot to also mention the weird colo...\n",
       "1  amazon                       THAT one didn't work either.\n",
       "2  amazon                                 Waste of 13 bucks.\n",
       "3  amazon  Product is useless, since it does not have eno...\n",
       "4  amazon  None of the three sizes they sent with the hea..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positive\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reads the data from the csv file\n",
    "x_train = pd.read_csv(\"./Dataset/x_train.csv\",header=None,names=['website','text'])\n",
    "y_train = pd.read_csv(\"./Dataset/y_train.csv\",header=None,names=['positive'])\n",
    "x_test = pd.read_csv(\"./Dataset/x_test.csv\",header=None,names=['website',\"text\"])\n",
    "y_test = pd.read_csv(\"./Dataset/y_test.csv\",header=None,names=['positive'])\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "display(x_train.head())\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a text pre processing class\n",
    "\n",
    "\n",
    "class TextPreprocessing:\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.bag_of_words = []\n",
    "        self.word_counts = {}\n",
    "        pass\n",
    "    def text_cleaning(self,text:str):\n",
    "\n",
    "        re_s = [\n",
    "            #remove the html tags\n",
    "            (r'<.*?>',''),\n",
    "            #remove the urls\n",
    "            (r'http\\S+|www.\\S+',''),\n",
    "            #remove the emails\n",
    "            (r'\\S+@\\S+',''),\n",
    "            #remove the new line\n",
    "            (r'\\n',''),\n",
    "            #remove the special characters\n",
    "            (r'[^\\w\\s]',''),\n",
    "            #remove the numbers\n",
    "            (r'\\d+',''),\n",
    "            #remove the stop words\n",
    "            (r'\\b\\w{1,2}\\b',''),\n",
    "            #remove the extra spaces\n",
    "            (r'\\s+',' ')\n",
    "        ] \n",
    "\n",
    "        for regex in re_s:\n",
    "            text = re.sub(regex[0],regex[1],text)\n",
    "        #convert the text to lower case\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    def text_stemming(self,text:str):\n",
    "        #create the stemmer object\n",
    "        stemmer = self.stemmer\n",
    "        #stem the text\n",
    "        text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "        return text\n",
    "    def text_lemmatization(self,text:str):\n",
    "        #create the lemmatizer object\n",
    "        lemmatizer = self.lemmatizer\n",
    "        text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "        return text\n",
    "\n",
    "    def text_tokenization(self,text:str):\n",
    "        #tokenize the text\n",
    "        text = text.split()\n",
    "        return text\n",
    "    def text_bag_of_words(self,text:str):\n",
    "        #create the bag of words\n",
    "        token = self.text_tokenization(text)\n",
    "        self.bag_of_words.extend(token)\n",
    "        self.bag_of_words = list(set(self.bag_of_words))\n",
    "        self.text_word_counts(token)\n",
    "        return self.bag_of_words\n",
    "    def text_word_counts(self,token:List[str]):\n",
    "        #create the word counts\n",
    "        # text = self.text_tokenization(text)\n",
    "        for word in token:\n",
    "            if word in self.word_counts:\n",
    "                self.word_counts[word] += 1\n",
    "            else:\n",
    "                self.word_counts[word] = 1\n",
    "        return self.word_counts\n",
    "    def __call__(self,text:str,bow:bool=True):\n",
    "        text = self.text_cleaning(text)\n",
    "        text = self.text_lemmatization(text)\n",
    "        if bow:\n",
    "            self.text_bag_of_words(text)\n",
    "\n",
    "        return text\n",
    "    def get_bag_of_words(self):\n",
    "        return self.bag_of_words,self.word_counts\n",
    "# define stratify k fold\n",
    "def stratified_kfold_cross_validation(x_train,y_train,clf,n_splits=3,):\n",
    "    skf = StratifiedKFold(n_splits=n_splits,random_state=42,shuffle=True)\n",
    "    evals = []\n",
    "    for train_index, test_index in skf.split(x_train[\"vec\"],y_train[\"positive\"]):\n",
    "        _x_train,_x_val = x_train[\"vec\"].iloc[train_index],x_train[\"vec\"].iloc[test_index]\n",
    "        _y_train,_y_val = y_train[\"positive\"].iloc[train_index],y_train[\"positive\"].iloc[test_index]\n",
    "        clf.fit(_x_train,_y_train)\n",
    "        y_pred = clf.predict(_x_val)\n",
    "        y_true = _y_val\n",
    "        evals.append({\n",
    "            \"accuracy\":accuracy_score(y_true,y_pred),\n",
    "            \"f1_score\":f1_score(y_true,y_pred),\n",
    "            \"precision\":precision_score(y_true,y_pred),\n",
    "            \"recall\":recall_score(y_true,y_pred)\n",
    "        })\n",
    "    return evals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_preprocess = TextPreprocessing()\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./models/lexvec.enwiki+newscrawl.300d.W.pos.vectors.gz', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th colspan=\"18\" halign=\"left\">vec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>vec0</th>\n",
       "      <th>vec1</th>\n",
       "      <th>vec2</th>\n",
       "      <th>vec3</th>\n",
       "      <th>vec4</th>\n",
       "      <th>vec5</th>\n",
       "      <th>vec6</th>\n",
       "      <th>...</th>\n",
       "      <th>vec290</th>\n",
       "      <th>vec291</th>\n",
       "      <th>vec292</th>\n",
       "      <th>vec293</th>\n",
       "      <th>vec294</th>\n",
       "      <th>vec295</th>\n",
       "      <th>vec296</th>\n",
       "      <th>vec297</th>\n",
       "      <th>vec298</th>\n",
       "      <th>vec299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>and forgot also mention the weird color effect...</td>\n",
       "      <td>0.378426</td>\n",
       "      <td>-0.060268</td>\n",
       "      <td>0.184822</td>\n",
       "      <td>0.151830</td>\n",
       "      <td>-0.297788</td>\n",
       "      <td>0.859612</td>\n",
       "      <td>-0.777484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469973</td>\n",
       "      <td>-0.304046</td>\n",
       "      <td>-1.065574</td>\n",
       "      <td>-1.171022</td>\n",
       "      <td>-0.422527</td>\n",
       "      <td>1.400082</td>\n",
       "      <td>-0.486773</td>\n",
       "      <td>-0.202140</td>\n",
       "      <td>-0.139517</td>\n",
       "      <td>-0.060523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>that one didnt work either</td>\n",
       "      <td>0.140225</td>\n",
       "      <td>0.041267</td>\n",
       "      <td>0.009939</td>\n",
       "      <td>0.282280</td>\n",
       "      <td>-0.046985</td>\n",
       "      <td>0.766434</td>\n",
       "      <td>-0.256409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274708</td>\n",
       "      <td>0.063017</td>\n",
       "      <td>-0.292846</td>\n",
       "      <td>-0.345118</td>\n",
       "      <td>0.105190</td>\n",
       "      <td>0.763756</td>\n",
       "      <td>-0.118280</td>\n",
       "      <td>0.137731</td>\n",
       "      <td>-0.208427</td>\n",
       "      <td>0.076719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>waste buck</td>\n",
       "      <td>-0.266811</td>\n",
       "      <td>-0.236225</td>\n",
       "      <td>-0.128274</td>\n",
       "      <td>0.126632</td>\n",
       "      <td>-0.088879</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.076802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>-0.011763</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.027326</td>\n",
       "      <td>0.110818</td>\n",
       "      <td>0.198335</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>-0.019087</td>\n",
       "      <td>0.027806</td>\n",
       "      <td>0.099427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>product useless since doe not have enough char...</td>\n",
       "      <td>0.444849</td>\n",
       "      <td>-0.627699</td>\n",
       "      <td>-0.006317</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>-0.420637</td>\n",
       "      <td>1.228025</td>\n",
       "      <td>-1.320413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428378</td>\n",
       "      <td>-0.800171</td>\n",
       "      <td>-0.776894</td>\n",
       "      <td>-2.037737</td>\n",
       "      <td>1.194447</td>\n",
       "      <td>1.492296</td>\n",
       "      <td>-0.052499</td>\n",
       "      <td>-0.863386</td>\n",
       "      <td>0.150174</td>\n",
       "      <td>-0.017175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>none the three size they sent with the headset...</td>\n",
       "      <td>0.392140</td>\n",
       "      <td>0.367241</td>\n",
       "      <td>0.398144</td>\n",
       "      <td>0.112205</td>\n",
       "      <td>-0.578090</td>\n",
       "      <td>1.134998</td>\n",
       "      <td>-0.503192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310214</td>\n",
       "      <td>-0.245398</td>\n",
       "      <td>-0.622091</td>\n",
       "      <td>-1.304139</td>\n",
       "      <td>-0.282142</td>\n",
       "      <td>0.053096</td>\n",
       "      <td>0.452793</td>\n",
       "      <td>-0.229530</td>\n",
       "      <td>-0.028972</td>\n",
       "      <td>-0.467039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  website                                               text  \\\n",
       "    value                                              value   \n",
       "0  amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1  amazon                       THAT one didn't work either.   \n",
       "2  amazon                                 Waste of 13 bucks.   \n",
       "3  amazon  Product is useless, since it does not have eno...   \n",
       "4  amazon  None of the three sizes they sent with the hea...   \n",
       "\n",
       "                                           processed       vec            \\\n",
       "                                               value      vec0      vec1   \n",
       "0  and forgot also mention the weird color effect...  0.378426 -0.060268   \n",
       "1                         that one didnt work either  0.140225  0.041267   \n",
       "2                                         waste buck -0.266811 -0.236225   \n",
       "3  product useless since doe not have enough char...  0.444849 -0.627699   \n",
       "4  none the three size they sent with the headset...  0.392140  0.367241   \n",
       "\n",
       "                                                     ...                      \\\n",
       "       vec2      vec3      vec4      vec5      vec6  ...    vec290    vec291   \n",
       "0  0.184822  0.151830 -0.297788  0.859612 -0.777484  ...  0.469973 -0.304046   \n",
       "1  0.009939  0.282280 -0.046985  0.766434 -0.256409  ...  0.274708  0.063017   \n",
       "2 -0.128274  0.126632 -0.088879  0.085906  0.076802  ...  0.243682 -0.011763   \n",
       "3 -0.006317  0.011628 -0.420637  1.228025 -1.320413  ...  0.428378 -0.800171   \n",
       "4  0.398144  0.112205 -0.578090  1.134998 -0.503192  ...  0.310214 -0.245398   \n",
       "\n",
       "                                                                         \\\n",
       "     vec292    vec293    vec294    vec295    vec296    vec297    vec298   \n",
       "0 -1.065574 -1.171022 -0.422527  1.400082 -0.486773 -0.202140 -0.139517   \n",
       "1 -0.292846 -0.345118  0.105190  0.763756 -0.118280  0.137731 -0.208427   \n",
       "2  0.011722  0.027326  0.110818  0.198335  0.000805 -0.019087  0.027806   \n",
       "3 -0.776894 -2.037737  1.194447  1.492296 -0.052499 -0.863386  0.150174   \n",
       "4 -0.622091 -1.304139 -0.282142  0.053096  0.452793 -0.229530 -0.028972   \n",
       "\n",
       "             \n",
       "     vec299  \n",
       "0 -0.060523  \n",
       "1  0.076719  \n",
       "2  0.099427  \n",
       "3 -0.017175  \n",
       "4 -0.467039  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##define pipeliens for the text preprocessing\n",
    "def vectorize_text(text):\n",
    "    #word2vec\n",
    "    vector = np.zeros(300)\n",
    "    for word in text.split():\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "    return vector\n",
    "def text_preprocessing_pipeline(df,t_preprocess:TextPreprocessing,bow=True):\n",
    "    df['processed'] = df['text'].apply(lambda x: t_preprocess(x,bow=bow))\n",
    "\n",
    "    \n",
    "    keys = [(\"vec\",\"vec\"+str(i)) for i in range(300)]\n",
    "    vec_df = pd.DataFrame(columns=keys)\n",
    "    df = df.join(vec_df)\n",
    "    df.columns=pd.MultiIndex.from_tuples([('website',\"value\"),('text','value'),('processed','value')]+keys)\n",
    "    df[keys] = pd.DataFrame(df[('processed','value')].apply(lambda x: vectorize_text(x)).tolist(), index= df.index)\n",
    "    #create multi index so vector columns can be accessed easily\n",
    "    return df\n",
    "\n",
    "x_train = text_preprocessing_pipeline(x_train,t_preprocess)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words counts 4179\n"
     ]
    }
   ],
   "source": [
    "bow, counts = t_preprocess.get_bag_of_words()\n",
    "print(\"bag of words counts\",len(bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models to train on\n",
    "models = [\n",
    "    (\"Random Forest\",RandomForestClassifier(n_estimators=100,random_state=42)),\n",
    "    (\"Logistic Regression\",LogisticRegression(random_state=42,solver='lbfgs', max_iter=1000)),\n",
    "    (\"SVM\",SVC(random_state=42)),\n",
    "    (\"KNN\",KNeighborsClassifier()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modelname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.712917</td>\n",
       "      <td>0.727312</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.765833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.812083</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>0.814768</td>\n",
       "      <td>0.808333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.768333</td>\n",
       "      <td>0.759056</td>\n",
       "      <td>0.790798</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.842083</td>\n",
       "      <td>0.837358</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy  f1_score  precision    recall\n",
       "modelname                                                   \n",
       "KNN                  0.712917  0.727312   0.692900  0.765833\n",
       "Logistic Regression  0.812083  0.811406   0.814768  0.808333\n",
       "Random Forest        0.768333  0.759056   0.790798  0.730000\n",
       "SVM                  0.842083  0.837358   0.862903  0.813333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do stratified k fold cross validation on the models\n",
    "evals = []\n",
    "for name,clf in models:\n",
    "    _eval = stratified_kfold_cross_validation(x_train,y_train,clf,n_splits=3)\n",
    "    _eval = pd.DataFrame(_eval)\n",
    "    _eval[\"modelname\"] = name\n",
    "    evals.append(_eval)\n",
    "#concat the evals\n",
    "eval_df = pd.concat(evals)\n",
    "results_df = eval_df.groupby(\"modelname\").mean()\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     SVM\n",
       "f1_score     SVM\n",
       "precision    SVM\n",
       "recall       SVM\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the best results\n",
    "results_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-24 12:57:37,113]\u001b[0m A new study created in memory with name: no-name-5c9287d7-2f3a-4a01-b9ac-1dd71550c8aa\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/metaltf/lib/python3.8/site-packages/optuna/progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83636416960447b9fcfaff4f419f7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#parameter tuning for SVM using optuna\n",
    "def objective(trial):\n",
    "    #define the parameters to tune\n",
    "    params = {\n",
    "        \"C\":trial.suggest_float(\"C\",1e-10,1e10),\n",
    "        \"kernel\":trial.suggest_categorical(\"kernel\",[\"linear\",\"rbf\"]),\n",
    "        \"gamma\":trial.suggest_categorical(\"gamma\",[\"scale\",\"auto\"]),\n",
    "        \"degree\":trial.suggest_int(\"degree\",1,5),\n",
    "        \"coef0\":trial.suggest_float(\"coef0\",1e-10,1e10)\n",
    "    }\n",
    "    #define the model\n",
    "    clf = SVC(**params,random_state=42)\n",
    "    #do stratified k fold cross validation\n",
    "    evals = stratified_kfold_cross_validation(x_train,y_train,clf,n_splits=3)\n",
    "    evals = pd.DataFrame(evals)\n",
    "    #get the mean of the evals\n",
    "    return evals[\"accuracy\"].mean()\n",
    "#optimize the model\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=50,#300 seconds or 50 trials whichever comes first\n",
    "    timeout=300,#300 seconds or 50 trials whichever comes first\n",
    "    # n_jobs=-1,# use all core\n",
    "    gc_after_trial=True, #garbage collect after each trial (free up memory)\n",
    "    show_progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the best model on the whole dataset\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(x_train[\"vec\"],y_train[\"positive\"])\n",
    "\n",
    "#test the model on the test set\n",
    "_x_test = text_preprocessing_pipeline(x_test,t_preprocess,bow=False)\n",
    "y_pred = clf.predict(_x_test[\"vec\"])\n",
    "y_true = y_test[\"positive\"]\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_true,y_pred)\n",
    "f1_score = f1_score(y_true,y_pred)\n",
    "precision = precision_score(y_true,y_pred)\n",
    "recall = recall_score(y_true,y_pred)\n",
    "confusion_mat = confusion_matrix(y_true,y_pred)\n",
    "print(\"accuracy\",accuracy)\n",
    "print(\"f1_score\",f1_score)\n",
    "print(\"precision\",precision)\n",
    "print(\"recall\",recall)\n",
    "print(\"confusion matrix\",confusion_mat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('metaltf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bb8f953e5a51e575a0614eea2cfd8668a4922a5c3f594783b10510e33be4fa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
