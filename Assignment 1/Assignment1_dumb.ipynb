{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ds tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from IPython.display import display\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Pipeline\n",
    "This code implements a sentiment analysis pipeline using Natural Language Toolkit (NLTK) and scikit-learn libraries in Python. The pipeline performs the following steps:\n",
    "\n",
    "Data pre-processing: The raw text data is pre-processed using various techniques, such as removing special characters and extra spaces, converting to lowercase, and lemmatizing the words.\n",
    "Feature extraction: The pre-processed text data is converted to a numerical feature matrix using the Term Frequency-Inverse Document Frequency (TF-IDF) algorithm.\n",
    "Model training and evaluation: Several machine learning models are trained and evaluated using the pre-processed and feature-extracted data. The models include Logistic Regression, Linear Support Vector Classification, Naive Bayes, Random Forest, Decision Tree, K-Nearest Neighbors, Support Vector Machines, Gradient Boosting, AdaBoost, Gaussian Process, and Gaussian Naive Bayes. The performance of each model is evaluated using k-fold cross-validation and various evaluation metrics, such as accuracy, precision, recall, and F1-score.\n",
    "The code is organized as follows:\n",
    "\n",
    "## Importing libraries\n",
    "The code begins by importing the necessary libraries, including NLTK, scikit-learn, pandas, and re. The NLTK library is used for lemmatization, and the scikit-learn library is used for feature extraction, model training, and evaluation. Pandas is used for data processing, and re is used for regular expression operations.\n",
    "\n",
    "## Data pre-processing\n",
    "The pre-processing of the text data is performed using the clean_text() function, which removes special characters and extra spaces, converts the text to lowercase, and lemmatizes the words using the NLTK library. The pre-processing function is then applied to the training and testing data using the preprocess_text() wrapper function.\n",
    "\n",
    "## Model training and evaluation\n",
    "The models are defined as a dictionary of scikit-learn classifiers, including Logistic Regression, Linear Support Vector Classification, Naive Bayes, Random Forest, Decision Tree, K-Nearest Neighbors, Support Vector Machines, Gradient Boosting, AdaBoost, Gaussian Process, and Gaussian Naive Bayes.\n",
    "\n",
    "The classifiers are trained and evaluated using k-fold cross-validation with 3 splits. The performance of each model is evaluated using various evaluation metrics, including accuracy, precision, recall, and F1-score. The results of the evaluation are stored in a Pandas DataFrame and displayed.\n",
    "\n",
    "The best-performing classifier is selected based on the F1-score, and its hyperparameters are tuned using Bayesian optimization. The best hyperparameters are then used to create a final model, which is trained on the entire training set and evaluated on the testing set.\n",
    "\n",
    "The performance of the final model is evaluated using various evaluation metrics, including accuracy, precision, recall, and F1-score, and the results are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 2) (2400, 1) (600, 2) (600, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  website                                               text\n",
       "0  amazon  Oh and I forgot to also mention the weird colo...\n",
       "1  amazon                       THAT one didn't work either.\n",
       "2  amazon                                 Waste of 13 bucks.\n",
       "3  amazon  Product is useless, since it does not have eno...\n",
       "4  amazon  None of the three sizes they sent with the hea..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positive\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data\n",
    "x_train = pd.read_csv(\"./Dataset/x_train.csv\",header=None,names=['website','text'])\n",
    "y_train = pd.read_csv(\"./Dataset/y_train.csv\",header=None,names=['positive'])\n",
    "x_test = pd.read_csv(\"./Dataset/x_test.csv\",header=None,names=['website',\"text\"])\n",
    "y_test = pd.read_csv(\"./Dataset/y_test.csv\",header=None,names=['positive'])\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "display(x_train.head())\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 : Text representation\n",
    "\n",
    "after we load the data, we need to clean it. we need to remove the stop words and the punctuation. we also need to stem the words. we will use the nltk library to do that.\n",
    "\n",
    "re is used to remove the punctuation and special character.\n",
    "WordnetLemmatizer is used to stem the words.\n",
    "\n",
    "then we will create pipeline to vectorize the data and do the classification.\n",
    "\n",
    "we will use the following classifiers:\n",
    "```python\n",
    "#import all of the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"LinearSVC\": LinearSVC(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"SGDClassifier\": SGDClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"NuSVC\": NuSVC(),\n",
    "    \"GaussianProcessClassifier\": GaussianProcessClassifier(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is a Python script for performing text classification using various machine learning classifiers. The script uses the Natural Language Toolkit (NLTK) library for lemmatization and the scikit-learn library for the machine learning classifiers and feature extraction. The dataset used for classification is assumed to be stored in two pandas dataframes, x_train and y_train for training data and x_test and y_test for testing data.\n",
    "\n",
    "The script performs the following steps:\n",
    "\n",
    "1. Imports necessary libraries: nltk, sklearn, pandas, re\n",
    "2. Downloads necessary packages from nltk.\n",
    "3. Defines a function lemmatize() that lemmatizes text using the WordNetLemmatizer from nltk.\n",
    "4. Defines a function clean_text() that cleans raw text by removing special characters, extra spaces, and lowercasing the text, and then calls the lemmatize() function to lemmatize the text.\n",
    "5. Defines a function preprocess_text() that applies the clean_text() function to a pandas Series of text data.\n",
    "6. Preprocesses the text data in the x_train and x_test dataframes using the preprocess_text() function.\n",
    "7. Defines a dictionary of classifiers to use for training and testing.\n",
    "8. Defines evaluation metrics, including accuracy, precision, recall, and f1-score.\n",
    "9. Loops over each classifier in the dictionary and performs a stratified k-fold cross-validation for training and testing. The pipeline includes a TfidfVectorizer for feature extraction, a FunctionTransformer to convert the sparse matrix output to a dense array, and the classifier being tested.\n",
    "10. Evaluates each classifier and stores the results in a dictionary that includes the classifier name and the evaluation metrics.\n",
    "11. Converts the results to a pandas dataframe, groups the results by classifier, calculates the mean evaluation metrics for each classifier, sorts the results by the f1-score, and displays the classifier with the highest f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/suchattangjarukij/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/suchattangjarukij/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.825779</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.815984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.817083</td>\n",
       "      <td>0.834012</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.811965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.812840</td>\n",
       "      <td>0.799167</td>\n",
       "      <td>0.805787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.802917</td>\n",
       "      <td>0.807356</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.801422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisiticRegression</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.810267</td>\n",
       "      <td>0.789167</td>\n",
       "      <td>0.799270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.800417</td>\n",
       "      <td>0.808887</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.797528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.791749</td>\n",
       "      <td>0.798333</td>\n",
       "      <td>0.793982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClassifier</th>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.812249</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.792567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.753750</td>\n",
       "      <td>0.731268</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.765052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.788572</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.754511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.745417</td>\n",
       "      <td>0.785717</td>\n",
       "      <td>0.675833</td>\n",
       "      <td>0.726014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.714167</td>\n",
       "      <td>0.740659</td>\n",
       "      <td>0.661667</td>\n",
       "      <td>0.698496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.690833</td>\n",
       "      <td>0.694513</td>\n",
       "      <td>0.681667</td>\n",
       "      <td>0.687947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.715487</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.682478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  precision    recall        f1\n",
       "classifier                                                         \n",
       "NuSVC                       0.818333   0.825779  0.807500  0.815984\n",
       "SVC                         0.817083   0.834012  0.791667  0.811965\n",
       "LinearSVC                   0.807500   0.812840  0.799167  0.805787\n",
       "BernoulliNB                 0.802917   0.807356  0.795833  0.801422\n",
       "LogisiticRegression         0.802083   0.810267  0.789167  0.799270\n",
       "MultinomialNB               0.800417   0.808887  0.786667  0.797528\n",
       "SGDClassifier               0.792500   0.791749  0.798333  0.793982\n",
       "GaussianProcessClassifier   0.797500   0.812249  0.775000  0.792567\n",
       "KNeighborsClassifier        0.753750   0.731268  0.803333  0.765052\n",
       "RandomForestClassifier      0.765000   0.788572  0.725000  0.754511\n",
       "GradientBoostingClassifier  0.745417   0.785717  0.675833  0.726014\n",
       "AdaBoostClassifier          0.714167   0.740659  0.661667  0.698496\n",
       "DecisionTreeClassifier      0.690833   0.694513  0.681667  0.687947\n",
       "GaussianNB                  0.696667   0.715487  0.653333  0.682478"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "accuracy     NuSVC\n",
       "precision      SVC\n",
       "recall       NuSVC\n",
       "f1           NuSVC\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#download nltk packages\n",
    "nltk.download('wordnet') \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    #lemmatize text\n",
    "    text = ' '.join([lemmatizer.lemmatize(w) for w in text.split()])\n",
    "    return text\n",
    "def clean_text(text):\n",
    "    #clean raw text\n",
    "    text_regex = [\n",
    "        (r'[^a-zA-Z0-9\\s]', ' '), #remove special characters\n",
    "        (r'\\s+', ' '), #remove extra spaces\n",
    "    ]\n",
    "    for regex, replace in text_regex:\n",
    "        text = re.sub(regex, replace, text)\n",
    "    #lowercase\n",
    "    text = text.lower()\n",
    "    #lemmatize\n",
    "    text = lemmatize(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "#preprocess text wrappwer for dataframe\n",
    "def preprocess_text(col: pd.Series) -> pd.Series:\n",
    "    return col.apply(clean_text)\n",
    "\n",
    "\n",
    "#preprocess text\n",
    "x_train['text_pre'] = preprocess_text(x_train['text'])\n",
    "x_test['text_pre'] = preprocess_text(x_test['text'])\n",
    "\n",
    "# defining classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"LinearSVC\": LinearSVC(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"SGDClassifier\": SGDClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"NuSVC\": NuSVC(),\n",
    "    \"GaussianProcessClassifier\": GaussianProcessClassifier(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "}\n",
    "\n",
    "# selecting baseline classifier to use for parameter tuning\n",
    "#defining evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "\n",
    "    # stratify kfold\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in skf.split(x_train['text_pre'], y_train['positive']):\n",
    "        x_train_fold, x_test_fold = x_train['text_pre'][train_index], x_train['text_pre'][test_index]\n",
    "        y_train_fold, y_test_fold = y_train['positive'][train_index], y_train['positive'][test_index]\n",
    "        #create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer()),\n",
    "            (\"todense\", FunctionTransformer(lambda x: x.toarray(), accept_sparse=True)),\n",
    "            ('clf', classifier),\n",
    "        ])\n",
    "        #fit pipeline\n",
    "        pipeline.fit(x_train_fold, y_train_fold)\n",
    "        #predict\n",
    "        y_pred = pipeline.predict(x_test_fold)\n",
    "        #evaluate\n",
    "        results.append({\n",
    "            \"classifier\": key,\n",
    "            \"accuracy\": accuracy_score(y_test_fold, y_pred),\n",
    "            \"precision\": precision_score(y_test_fold, y_pred),\n",
    "            \"recall\": recall_score(y_test_fold, y_pred),\n",
    "            \"f1\": f1_score(y_test_fold, y_pred),\n",
    "\n",
    "        })\n",
    "   \n",
    "#convert results to dataframe\n",
    "results = pd.DataFrame(results)\n",
    "# results\n",
    "res = results.groupby(\"classifier\").mean().sort_values(\"f1\", ascending=False)\n",
    "display(res)\n",
    "display(res.idxmax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter tuning\n",
    "This next block of code performs hyperparameter tuning for a classifier using the Optuna library. The objective function is defined as objective(trial) and takes a trial object as its input. The function first defines a set of hyperparameters to optimize, which includes the degree of the polynomial kernel, the decision function shape, the kernel type, and the random state. The StratifiedKFold method is used to split the data into three folds for cross-validation, and the Pipeline method is used to create a pipeline consisting of a TfidfVectorizer, a NuSVC classifier, and some hyperparameters to optimize.\n",
    "\n",
    "The pipeline.set_params(**parameters) method is called to set the values of the hyperparameters defined in the objective function. The pipeline.fit(x_train_fold, y_train_fold) method is then used to fit the pipeline to the training data, and the pipeline.predict(x_test_fold) method is used to predict the class labels of the test data. The f1_score(y_test_fold, y_pred) method is used to compute the F1 score of the predictions, and the mean F1 score of the three folds is returned as the objective value.\n",
    "\n",
    "The optuna.create_study(direction=\"maximize\") method is used to create a study object, and the study.optimize(objective, n_trials=50,timeout=300,n_jobs=-1) method is used to run 50 trials with a maximum time of 300 seconds per trial in parallel using all available cores. The objective of the hyperparameter tuning is to find the combination of hyperparameters that will maximize the F1 score of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-24 15:35:03,885]\u001b[0m A new study created in memory with name: no-name-e782ccd9-f501-44bb-ad41-9feee68b5bba\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:35:41,231]\u001b[0m Trial 6 finished with value: 0.800377301704561 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'sigmoid'}. Best is trial 6 with value: 0.800377301704561.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:35:41,268]\u001b[0m Trial 4 finished with value: 0.800377301704561 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'sigmoid'}. Best is trial 6 with value: 0.800377301704561.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:35:43,214]\u001b[0m Trial 0 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'poly'}. Best is trial 0 with value: 0.8052212179274479.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:35:43,325]\u001b[0m Trial 3 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'linear'}. Best is trial 0 with value: 0.8052212179274479.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:35:51,525]\u001b[0m Trial 2 finished with value: 0.8148084445713843 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'poly'}. Best is trial 2 with value: 0.8148084445713843.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:35:52,228]\u001b[0m Trial 1 finished with value: 0.7966876921228837 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'poly'}. Best is trial 2 with value: 0.8148084445713843.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:00,074]\u001b[0m Trial 7 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:00,153]\u001b[0m Trial 5 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:26,426]\u001b[0m Trial 10 finished with value: 0.8148084445713843 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:33,127]\u001b[0m Trial 9 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:33,347]\u001b[0m Trial 8 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:35,258]\u001b[0m Trial 11 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:41,312]\u001b[0m Trial 15 finished with value: 0.8148084445713843 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:42,410]\u001b[0m Trial 12 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:42,988]\u001b[0m Trial 13 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:36:49,558]\u001b[0m Trial 14 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:07,322]\u001b[0m Trial 16 finished with value: 0.7966876921228837 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:17,327]\u001b[0m Trial 22 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'linear'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:22,823]\u001b[0m Trial 18 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:22,874]\u001b[0m Trial 17 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:24,220]\u001b[0m Trial 23 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'linear'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:24,869]\u001b[0m Trial 19 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:31,262]\u001b[0m Trial 20 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:32,200]\u001b[0m Trial 21 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:41,494]\u001b[0m Trial 24 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'linear'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:37:56,168]\u001b[0m Trial 27 finished with value: 0.800377301704561 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'sigmoid'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:38:07,194]\u001b[0m Trial 31 finished with value: 0.800377301704561 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'sigmoid'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:38:09,356]\u001b[0m Trial 25 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:38:15,490]\u001b[0m Trial 26 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:38:17,163]\u001b[0m Trial 28 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:38:17,913]\u001b[0m Trial 29 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 3, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:38:18,206]\u001b[0m Trial 32 finished with value: 0.800377301704561 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'sigmoid'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:38:25,070]\u001b[0m Trial 30 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:38:50,368]\u001b[0m Trial 33 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:00,693]\u001b[0m Trial 34 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:02,709]\u001b[0m Trial 35 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:07,683]\u001b[0m Trial 36 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:08,973]\u001b[0m Trial 37 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:09,849]\u001b[0m Trial 38 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:10,159]\u001b[0m Trial 39 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:18,506]\u001b[0m Trial 40 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:47,259]\u001b[0m Trial 41 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:49,121]\u001b[0m Trial 44 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:50,388]\u001b[0m Trial 45 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:51,005]\u001b[0m Trial 46 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:51,245]\u001b[0m Trial 47 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:55,619]\u001b[0m Trial 42 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 2, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:56,836]\u001b[0m Trial 43 finished with value: 0.8159844401882618 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovo', 'clf__kernel': 'rbf'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:39:57,221]\u001b[0m Trial 48 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n",
      "\u001b[32m[I 2023-03-24 15:40:12,795]\u001b[0m Trial 49 finished with value: 0.8052212179274479 and parameters: {'clf__degree': 1, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'poly'}. Best is trial 7 with value: 0.8159844401882618.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# tune parameters for best classifier using optuna\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # define parameters to tune\n",
    "    parameters = {\n",
    "        # \"tfidf__ngram_range\": trial.suggest_categorical(\"tfidf__ngram_range\", [(1,1), (1,2), (1,3)]),\n",
    "        # \"tfidf__max_df\": trial.suggest_float(\"tfidf__max_df\", 0.5, 1.0),\n",
    "        # \"tfidf__min_df\": trial.suggest_float(\"tfidf__min_df\", 0.0, 0.5),\n",
    "        \"clf__degree\": trial.suggest_int(\"clf__degree\", 1, 3),\n",
    "        \"clf__decision_function_shape\": trial.suggest_categorical(\"clf__decision_function_shape\", [\"ovo\", \"ovr\"]),\n",
    "        \"clf__kernel\": trial.suggest_categorical(\"clf__kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "        \"clf__random_state\": 42,\n",
    "    }\n",
    "    # create pipeline for each stratified kfold\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    f1 = []\n",
    "    for train_index, test_index in skf.split(x_train['text_pre'], y_train['positive']):\n",
    "        x_train_fold, x_test_fold = x_train['text_pre'][train_index], x_train['text_pre'][test_index]\n",
    "        y_train_fold, y_test_fold = y_train['positive'][train_index], y_train['positive'][test_index]\n",
    "        # create pipeline\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer()),\n",
    "            (\"todense\", FunctionTransformer(lambda x: x.toarray(), accept_sparse=True)),\n",
    "            ('clf', NuSVC()),\n",
    "        ])\n",
    "        # fit pipeline\n",
    "        pipeline.set_params(**parameters)\n",
    "        pipeline.fit(x_train_fold, y_train_fold)\n",
    "        # predict\n",
    "        y_pred = pipeline.predict(x_test_fold)\n",
    "        # evaluate\n",
    "        f1.append(f1_score(y_test_fold, y_pred))\n",
    "\n",
    "    return np.mean(f1)\n",
    "\n",
    "# create study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# optimize\n",
    "study.optimize(objective, n_trials=50,timeout=300,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_clf__decision_function_shape</th>\n",
       "      <th>params_clf__degree</th>\n",
       "      <th>params_clf__kernel</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:35:03.887321</td>\n",
       "      <td>2023-03-24 15:35:43.214127</td>\n",
       "      <td>0 days 00:00:39.326806</td>\n",
       "      <td>ovr</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.796688</td>\n",
       "      <td>2023-03-24 15:35:03.889417</td>\n",
       "      <td>2023-03-24 15:35:52.227675</td>\n",
       "      <td>0 days 00:00:48.338258</td>\n",
       "      <td>ovo</td>\n",
       "      <td>3</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.814808</td>\n",
       "      <td>2023-03-24 15:35:03.890842</td>\n",
       "      <td>2023-03-24 15:35:51.525094</td>\n",
       "      <td>0 days 00:00:47.634252</td>\n",
       "      <td>ovr</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:35:03.891439</td>\n",
       "      <td>2023-03-24 15:35:43.324992</td>\n",
       "      <td>0 days 00:00:39.433553</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.800377</td>\n",
       "      <td>2023-03-24 15:35:03.893095</td>\n",
       "      <td>2023-03-24 15:35:41.268155</td>\n",
       "      <td>0 days 00:00:37.375060</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:35:03.894054</td>\n",
       "      <td>2023-03-24 15:36:00.153451</td>\n",
       "      <td>0 days 00:00:56.259397</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.800377</td>\n",
       "      <td>2023-03-24 15:35:03.897429</td>\n",
       "      <td>2023-03-24 15:35:41.229281</td>\n",
       "      <td>0 days 00:00:37.331852</td>\n",
       "      <td>ovr</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:35:03.898177</td>\n",
       "      <td>2023-03-24 15:36:00.074200</td>\n",
       "      <td>0 days 00:00:56.176023</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:35:41.256894</td>\n",
       "      <td>2023-03-24 15:36:33.347713</td>\n",
       "      <td>0 days 00:00:52.090819</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:35:41.283030</td>\n",
       "      <td>2023-03-24 15:36:33.126601</td>\n",
       "      <td>0 days 00:00:51.843571</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.814808</td>\n",
       "      <td>2023-03-24 15:35:43.219452</td>\n",
       "      <td>2023-03-24 15:36:26.426008</td>\n",
       "      <td>0 days 00:00:43.206556</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:35:43.328900</td>\n",
       "      <td>2023-03-24 15:36:35.258034</td>\n",
       "      <td>0 days 00:00:51.929134</td>\n",
       "      <td>ovr</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:35:51.538469</td>\n",
       "      <td>2023-03-24 15:36:42.410421</td>\n",
       "      <td>0 days 00:00:50.871952</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:35:52.234217</td>\n",
       "      <td>2023-03-24 15:36:42.988086</td>\n",
       "      <td>0 days 00:00:50.753869</td>\n",
       "      <td>ovo</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:36:00.077835</td>\n",
       "      <td>2023-03-24 15:36:49.558132</td>\n",
       "      <td>0 days 00:00:49.480297</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.814808</td>\n",
       "      <td>2023-03-24 15:36:00.157653</td>\n",
       "      <td>2023-03-24 15:36:41.311946</td>\n",
       "      <td>0 days 00:00:41.154293</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.796688</td>\n",
       "      <td>2023-03-24 15:36:26.432416</td>\n",
       "      <td>2023-03-24 15:37:07.321908</td>\n",
       "      <td>0 days 00:00:40.889492</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:36:33.135426</td>\n",
       "      <td>2023-03-24 15:37:22.874152</td>\n",
       "      <td>0 days 00:00:49.738726</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:36:33.351991</td>\n",
       "      <td>2023-03-24 15:37:22.823055</td>\n",
       "      <td>0 days 00:00:49.471064</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:36:35.261113</td>\n",
       "      <td>2023-03-24 15:37:24.868775</td>\n",
       "      <td>0 days 00:00:49.607662</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:36:41.318691</td>\n",
       "      <td>2023-03-24 15:37:31.262662</td>\n",
       "      <td>0 days 00:00:49.943971</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:36:42.413359</td>\n",
       "      <td>2023-03-24 15:37:32.199898</td>\n",
       "      <td>0 days 00:00:49.786539</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:36:42.991873</td>\n",
       "      <td>2023-03-24 15:37:17.326889</td>\n",
       "      <td>0 days 00:00:34.335016</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>linear</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:36:49.561975</td>\n",
       "      <td>2023-03-24 15:37:24.220320</td>\n",
       "      <td>0 days 00:00:34.658345</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>linear</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:37:07.334091</td>\n",
       "      <td>2023-03-24 15:37:41.493933</td>\n",
       "      <td>0 days 00:00:34.159842</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>linear</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:37:17.332754</td>\n",
       "      <td>2023-03-24 15:38:09.355799</td>\n",
       "      <td>0 days 00:00:52.023045</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:37:22.834843</td>\n",
       "      <td>2023-03-24 15:38:15.490043</td>\n",
       "      <td>0 days 00:00:52.655200</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.800377</td>\n",
       "      <td>2023-03-24 15:37:22.890262</td>\n",
       "      <td>2023-03-24 15:37:56.166292</td>\n",
       "      <td>0 days 00:00:33.276030</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:37:24.224492</td>\n",
       "      <td>2023-03-24 15:38:17.162701</td>\n",
       "      <td>0 days 00:00:52.938209</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:37:24.875048</td>\n",
       "      <td>2023-03-24 15:38:17.913689</td>\n",
       "      <td>0 days 00:00:53.038641</td>\n",
       "      <td>ovr</td>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:37:31.267533</td>\n",
       "      <td>2023-03-24 15:38:25.070429</td>\n",
       "      <td>0 days 00:00:53.802896</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.800377</td>\n",
       "      <td>2023-03-24 15:37:32.203329</td>\n",
       "      <td>2023-03-24 15:38:07.194437</td>\n",
       "      <td>0 days 00:00:34.991108</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.800377</td>\n",
       "      <td>2023-03-24 15:37:41.502632</td>\n",
       "      <td>2023-03-24 15:38:18.205828</td>\n",
       "      <td>0 days 00:00:36.703196</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:37:56.175302</td>\n",
       "      <td>2023-03-24 15:38:50.368419</td>\n",
       "      <td>0 days 00:00:54.193117</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:38:07.201987</td>\n",
       "      <td>2023-03-24 15:39:00.692922</td>\n",
       "      <td>0 days 00:00:53.490935</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:38:09.359436</td>\n",
       "      <td>2023-03-24 15:39:02.708949</td>\n",
       "      <td>0 days 00:00:53.349513</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:38:15.506920</td>\n",
       "      <td>2023-03-24 15:39:07.683424</td>\n",
       "      <td>0 days 00:00:52.176504</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:38:17.166745</td>\n",
       "      <td>2023-03-24 15:39:08.973044</td>\n",
       "      <td>0 days 00:00:51.806299</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:38:17.924451</td>\n",
       "      <td>2023-03-24 15:39:09.849194</td>\n",
       "      <td>0 days 00:00:51.924743</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:38:18.210308</td>\n",
       "      <td>2023-03-24 15:39:10.159147</td>\n",
       "      <td>0 days 00:00:51.948839</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:38:25.074278</td>\n",
       "      <td>2023-03-24 15:39:18.505935</td>\n",
       "      <td>0 days 00:00:53.431657</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:38:50.388158</td>\n",
       "      <td>2023-03-24 15:39:47.258481</td>\n",
       "      <td>0 days 00:00:56.870323</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:39:00.697704</td>\n",
       "      <td>2023-03-24 15:39:55.619105</td>\n",
       "      <td>0 days 00:00:54.921401</td>\n",
       "      <td>ovo</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.815984</td>\n",
       "      <td>2023-03-24 15:39:02.713999</td>\n",
       "      <td>2023-03-24 15:39:56.836556</td>\n",
       "      <td>0 days 00:00:54.122557</td>\n",
       "      <td>ovo</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:39:07.695509</td>\n",
       "      <td>2023-03-24 15:39:49.121388</td>\n",
       "      <td>0 days 00:00:41.425879</td>\n",
       "      <td>ovo</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:39:08.982844</td>\n",
       "      <td>2023-03-24 15:39:50.388580</td>\n",
       "      <td>0 days 00:00:41.405736</td>\n",
       "      <td>ovo</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:39:09.853812</td>\n",
       "      <td>2023-03-24 15:39:51.005479</td>\n",
       "      <td>0 days 00:00:41.151667</td>\n",
       "      <td>ovo</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:39:10.168441</td>\n",
       "      <td>2023-03-24 15:39:51.245587</td>\n",
       "      <td>0 days 00:00:41.077146</td>\n",
       "      <td>ovo</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:39:18.513888</td>\n",
       "      <td>2023-03-24 15:39:57.221769</td>\n",
       "      <td>0 days 00:00:38.707881</td>\n",
       "      <td>ovr</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>2023-03-24 15:39:47.268046</td>\n",
       "      <td>2023-03-24 15:40:12.794724</td>\n",
       "      <td>0 days 00:00:25.526678</td>\n",
       "      <td>ovr</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.805221 2023-03-24 15:35:03.887321 2023-03-24 15:35:43.214127   \n",
       "1        1  0.796688 2023-03-24 15:35:03.889417 2023-03-24 15:35:52.227675   \n",
       "2        2  0.814808 2023-03-24 15:35:03.890842 2023-03-24 15:35:51.525094   \n",
       "3        3  0.805221 2023-03-24 15:35:03.891439 2023-03-24 15:35:43.324992   \n",
       "4        4  0.800377 2023-03-24 15:35:03.893095 2023-03-24 15:35:41.268155   \n",
       "5        5  0.815984 2023-03-24 15:35:03.894054 2023-03-24 15:36:00.153451   \n",
       "6        6  0.800377 2023-03-24 15:35:03.897429 2023-03-24 15:35:41.229281   \n",
       "7        7  0.815984 2023-03-24 15:35:03.898177 2023-03-24 15:36:00.074200   \n",
       "8        8  0.815984 2023-03-24 15:35:41.256894 2023-03-24 15:36:33.347713   \n",
       "9        9  0.815984 2023-03-24 15:35:41.283030 2023-03-24 15:36:33.126601   \n",
       "10      10  0.814808 2023-03-24 15:35:43.219452 2023-03-24 15:36:26.426008   \n",
       "11      11  0.815984 2023-03-24 15:35:43.328900 2023-03-24 15:36:35.258034   \n",
       "12      12  0.815984 2023-03-24 15:35:51.538469 2023-03-24 15:36:42.410421   \n",
       "13      13  0.815984 2023-03-24 15:35:52.234217 2023-03-24 15:36:42.988086   \n",
       "14      14  0.815984 2023-03-24 15:36:00.077835 2023-03-24 15:36:49.558132   \n",
       "15      15  0.814808 2023-03-24 15:36:00.157653 2023-03-24 15:36:41.311946   \n",
       "16      16  0.796688 2023-03-24 15:36:26.432416 2023-03-24 15:37:07.321908   \n",
       "17      17  0.815984 2023-03-24 15:36:33.135426 2023-03-24 15:37:22.874152   \n",
       "18      18  0.815984 2023-03-24 15:36:33.351991 2023-03-24 15:37:22.823055   \n",
       "19      19  0.815984 2023-03-24 15:36:35.261113 2023-03-24 15:37:24.868775   \n",
       "20      20  0.815984 2023-03-24 15:36:41.318691 2023-03-24 15:37:31.262662   \n",
       "21      21  0.815984 2023-03-24 15:36:42.413359 2023-03-24 15:37:32.199898   \n",
       "22      22  0.805221 2023-03-24 15:36:42.991873 2023-03-24 15:37:17.326889   \n",
       "23      23  0.805221 2023-03-24 15:36:49.561975 2023-03-24 15:37:24.220320   \n",
       "24      24  0.805221 2023-03-24 15:37:07.334091 2023-03-24 15:37:41.493933   \n",
       "25      25  0.815984 2023-03-24 15:37:17.332754 2023-03-24 15:38:09.355799   \n",
       "26      26  0.815984 2023-03-24 15:37:22.834843 2023-03-24 15:38:15.490043   \n",
       "27      27  0.800377 2023-03-24 15:37:22.890262 2023-03-24 15:37:56.166292   \n",
       "28      28  0.815984 2023-03-24 15:37:24.224492 2023-03-24 15:38:17.162701   \n",
       "29      29  0.815984 2023-03-24 15:37:24.875048 2023-03-24 15:38:17.913689   \n",
       "30      30  0.815984 2023-03-24 15:37:31.267533 2023-03-24 15:38:25.070429   \n",
       "31      31  0.800377 2023-03-24 15:37:32.203329 2023-03-24 15:38:07.194437   \n",
       "32      32  0.800377 2023-03-24 15:37:41.502632 2023-03-24 15:38:18.205828   \n",
       "33      33  0.815984 2023-03-24 15:37:56.175302 2023-03-24 15:38:50.368419   \n",
       "34      34  0.815984 2023-03-24 15:38:07.201987 2023-03-24 15:39:00.692922   \n",
       "35      35  0.815984 2023-03-24 15:38:09.359436 2023-03-24 15:39:02.708949   \n",
       "36      36  0.815984 2023-03-24 15:38:15.506920 2023-03-24 15:39:07.683424   \n",
       "37      37  0.815984 2023-03-24 15:38:17.166745 2023-03-24 15:39:08.973044   \n",
       "38      38  0.815984 2023-03-24 15:38:17.924451 2023-03-24 15:39:09.849194   \n",
       "39      39  0.815984 2023-03-24 15:38:18.210308 2023-03-24 15:39:10.159147   \n",
       "40      40  0.815984 2023-03-24 15:38:25.074278 2023-03-24 15:39:18.505935   \n",
       "41      41  0.815984 2023-03-24 15:38:50.388158 2023-03-24 15:39:47.258481   \n",
       "42      42  0.815984 2023-03-24 15:39:00.697704 2023-03-24 15:39:55.619105   \n",
       "43      43  0.815984 2023-03-24 15:39:02.713999 2023-03-24 15:39:56.836556   \n",
       "44      44  0.805221 2023-03-24 15:39:07.695509 2023-03-24 15:39:49.121388   \n",
       "45      45  0.805221 2023-03-24 15:39:08.982844 2023-03-24 15:39:50.388580   \n",
       "46      46  0.805221 2023-03-24 15:39:09.853812 2023-03-24 15:39:51.005479   \n",
       "47      47  0.805221 2023-03-24 15:39:10.168441 2023-03-24 15:39:51.245587   \n",
       "48      48  0.805221 2023-03-24 15:39:18.513888 2023-03-24 15:39:57.221769   \n",
       "49      49  0.805221 2023-03-24 15:39:47.268046 2023-03-24 15:40:12.794724   \n",
       "\n",
       "                 duration params_clf__decision_function_shape  \\\n",
       "0  0 days 00:00:39.326806                                 ovr   \n",
       "1  0 days 00:00:48.338258                                 ovo   \n",
       "2  0 days 00:00:47.634252                                 ovr   \n",
       "3  0 days 00:00:39.433553                                 ovo   \n",
       "4  0 days 00:00:37.375060                                 ovo   \n",
       "5  0 days 00:00:56.259397                                 ovr   \n",
       "6  0 days 00:00:37.331852                                 ovr   \n",
       "7  0 days 00:00:56.176023                                 ovr   \n",
       "8  0 days 00:00:52.090819                                 ovo   \n",
       "9  0 days 00:00:51.843571                                 ovo   \n",
       "10 0 days 00:00:43.206556                                 ovo   \n",
       "11 0 days 00:00:51.929134                                 ovr   \n",
       "12 0 days 00:00:50.871952                                 ovo   \n",
       "13 0 days 00:00:50.753869                                 ovo   \n",
       "14 0 days 00:00:49.480297                                 ovr   \n",
       "15 0 days 00:00:41.154293                                 ovo   \n",
       "16 0 days 00:00:40.889492                                 ovr   \n",
       "17 0 days 00:00:49.738726                                 ovr   \n",
       "18 0 days 00:00:49.471064                                 ovr   \n",
       "19 0 days 00:00:49.607662                                 ovr   \n",
       "20 0 days 00:00:49.943971                                 ovr   \n",
       "21 0 days 00:00:49.786539                                 ovr   \n",
       "22 0 days 00:00:34.335016                                 ovr   \n",
       "23 0 days 00:00:34.658345                                 ovr   \n",
       "24 0 days 00:00:34.159842                                 ovr   \n",
       "25 0 days 00:00:52.023045                                 ovr   \n",
       "26 0 days 00:00:52.655200                                 ovr   \n",
       "27 0 days 00:00:33.276030                                 ovr   \n",
       "28 0 days 00:00:52.938209                                 ovr   \n",
       "29 0 days 00:00:53.038641                                 ovr   \n",
       "30 0 days 00:00:53.802896                                 ovo   \n",
       "31 0 days 00:00:34.991108                                 ovo   \n",
       "32 0 days 00:00:36.703196                                 ovo   \n",
       "33 0 days 00:00:54.193117                                 ovo   \n",
       "34 0 days 00:00:53.490935                                 ovo   \n",
       "35 0 days 00:00:53.349513                                 ovo   \n",
       "36 0 days 00:00:52.176504                                 ovo   \n",
       "37 0 days 00:00:51.806299                                 ovo   \n",
       "38 0 days 00:00:51.924743                                 ovo   \n",
       "39 0 days 00:00:51.948839                                 ovo   \n",
       "40 0 days 00:00:53.431657                                 ovo   \n",
       "41 0 days 00:00:56.870323                                 ovo   \n",
       "42 0 days 00:00:54.921401                                 ovo   \n",
       "43 0 days 00:00:54.122557                                 ovo   \n",
       "44 0 days 00:00:41.425879                                 ovo   \n",
       "45 0 days 00:00:41.405736                                 ovo   \n",
       "46 0 days 00:00:41.151667                                 ovo   \n",
       "47 0 days 00:00:41.077146                                 ovo   \n",
       "48 0 days 00:00:38.707881                                 ovr   \n",
       "49 0 days 00:00:25.526678                                 ovr   \n",
       "\n",
       "    params_clf__degree params_clf__kernel     state  \n",
       "0                    1               poly  COMPLETE  \n",
       "1                    3               poly  COMPLETE  \n",
       "2                    2               poly  COMPLETE  \n",
       "3                    2             linear  COMPLETE  \n",
       "4                    2            sigmoid  COMPLETE  \n",
       "5                    3                rbf  COMPLETE  \n",
       "6                    1            sigmoid  COMPLETE  \n",
       "7                    3                rbf  COMPLETE  \n",
       "8                    2                rbf  COMPLETE  \n",
       "9                    2                rbf  COMPLETE  \n",
       "10                   2               poly  COMPLETE  \n",
       "11                   1                rbf  COMPLETE  \n",
       "12                   2                rbf  COMPLETE  \n",
       "13                   1                rbf  COMPLETE  \n",
       "14                   3                rbf  COMPLETE  \n",
       "15                   2               poly  COMPLETE  \n",
       "16                   3               poly  COMPLETE  \n",
       "17                   3                rbf  COMPLETE  \n",
       "18                   3                rbf  COMPLETE  \n",
       "19                   3                rbf  COMPLETE  \n",
       "20                   3                rbf  COMPLETE  \n",
       "21                   3                rbf  COMPLETE  \n",
       "22                   3             linear  COMPLETE  \n",
       "23                   3             linear  COMPLETE  \n",
       "24                   3             linear  COMPLETE  \n",
       "25                   3                rbf  COMPLETE  \n",
       "26                   3                rbf  COMPLETE  \n",
       "27                   3            sigmoid  COMPLETE  \n",
       "28                   3                rbf  COMPLETE  \n",
       "29                   3                rbf  COMPLETE  \n",
       "30                   2                rbf  COMPLETE  \n",
       "31                   2            sigmoid  COMPLETE  \n",
       "32                   2            sigmoid  COMPLETE  \n",
       "33                   2                rbf  COMPLETE  \n",
       "34                   2                rbf  COMPLETE  \n",
       "35                   2                rbf  COMPLETE  \n",
       "36                   2                rbf  COMPLETE  \n",
       "37                   2                rbf  COMPLETE  \n",
       "38                   2                rbf  COMPLETE  \n",
       "39                   2                rbf  COMPLETE  \n",
       "40                   2                rbf  COMPLETE  \n",
       "41                   2                rbf  COMPLETE  \n",
       "42                   2                rbf  COMPLETE  \n",
       "43                   1                rbf  COMPLETE  \n",
       "44                   1               poly  COMPLETE  \n",
       "45                   1               poly  COMPLETE  \n",
       "46                   1               poly  COMPLETE  \n",
       "47                   1               poly  COMPLETE  \n",
       "48                   1               poly  COMPLETE  \n",
       "49                   1               poly  COMPLETE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model with Hyperparameter from optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "# create pipeline with best parameters\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    (\"todense\", FunctionTransformer(lambda x: x.toarray(), accept_sparse=True)),\n",
    "    ('clf', NuSVC()),\n",
    "])\n",
    "pipeline.set_params(**best_params,clf__probability=True)\n",
    "pipeline.fit(x_train['text_pre'], y_train['positive'])\n",
    "y_pred = pipeline.predict(x_test['text_pre'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       300\n",
      "           1       0.87      0.77      0.82       300\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.83      0.83      0.83       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "accuracy:  0.83\n",
      "precision:  0.8721804511278195\n",
      "recall:  0.7733333333333333\n",
      "f1:  0.8197879858657243\n",
      "confusion matrix:  [[266  34]\n",
      " [ 68 232]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test['positive'], y_pred))\n",
    "\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y_test['positive'], y_pred))\n",
    "print(\"precision: \", precision_score(y_test['positive'], y_pred))\n",
    "print(\"recall: \", recall_score(y_test['positive'], y_pred))\n",
    "print(\"f1: \", f1_score(y_test['positive'], y_pred))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test['positive'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF representation explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '10' '100' ... 'zero' 'zillion' 'zombie']\n",
      "(4166,)\n"
     ]
    }
   ],
   "source": [
    "# explaining tfidf vectorizer from pipeline\n",
    "# get feature names\n",
    "feature_names = pipeline.named_steps['tfidf'].get_feature_names_out()\n",
    "# # get coefficients\n",
    "# coef = pipeline.named_steps['clf'].coef_\n",
    "# # get top 10 features\n",
    "# top10 = np.argsort(coef[0])[-10:]\n",
    "# # get bottom 10 features\n",
    "# bottom10 = np.argsort(coef[0])[:10]\n",
    "# # print top 10 features\n",
    "# print(\"top 10 features\")\n",
    "# for i in top10:\n",
    "#     print(feature_names[i])\n",
    "# # print bottom 10 features\n",
    "# print(\"bottom 10 features\")\n",
    "# for i in bottom10:\n",
    "#     print(feature_names[i])\n",
    "print(feature_names)\n",
    "print(feature_names.shape)\n",
    "\n",
    "pipeline.named_steps['tfidf']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eli5.show_weights(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "    <div style=\"background-color: #fdd; padding: 0.5em;\">\n",
       "        Error: only kernel='linear' is currently supported for libsvm-based classifiers\n",
       "    </div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "eli5.show_weights(pipeline.named_steps['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction analysis\n",
    "This code creates a dataframe that includes the true labels, predicted labels, and predicted probabilities of the test set. It then adds the original text of each sentence in the test set to the dataframe. The code then selects the false positive predictions and ranks them by the probability of their positive prediction. The resulting dataframe is displayed, showing the top 10 false positives with the highest probability of being positive. Finally, the code selects the false negative predictions and ranks them by the probability of their negative prediction. The resulting dataframe is displayed, showing the top 10 false negatives with the lowest probability of being negative. This allows for an analysis of which types of sentences the model is misclassifying and may provide insights for improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_proba</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958781</td>\n",
       "      <td>It's this pandering to the audience that sabot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909585</td>\n",
       "      <td>This movie now joins Revenge of the Boogeyman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889589</td>\n",
       "      <td>The only consistent thread holding the series ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875319</td>\n",
       "      <td>It defeats the purpose of a bluetooth headset.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865292</td>\n",
       "      <td>The directing and the cinematography aren't qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847603</td>\n",
       "      <td>The film is way too long.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847515</td>\n",
       "      <td>It's AGGRAVATING!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.741901</td>\n",
       "      <td>This movie suffered because of the writing, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733195</td>\n",
       "      <td>This item worked great, but it broke after 6 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732823</td>\n",
       "      <td>Maybe it's just their Vegetarian fare, but I'v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true  y_pred  y_pred_proba  \\\n",
       "286       0       1      0.958781   \n",
       "259       0       1      0.909585   \n",
       "232       0       1      0.889589   \n",
       "58        0       1      0.875319   \n",
       "244       0       1      0.865292   \n",
       "214       0       1      0.847603   \n",
       "27        0       1      0.847515   \n",
       "203       0       1      0.741901   \n",
       "52        0       1      0.733195   \n",
       "469       0       1      0.732823   \n",
       "\n",
       "                                                  text  \n",
       "286  It's this pandering to the audience that sabot...  \n",
       "259  This movie now joins Revenge of the Boogeyman ...  \n",
       "232  The only consistent thread holding the series ...  \n",
       "58      It defeats the purpose of a bluetooth headset.  \n",
       "244  The directing and the cinematography aren't qu...  \n",
       "214                        The film is way too long.    \n",
       "27                                   It's AGGRAVATING!  \n",
       "203  This movie suffered because of the writing, it...  \n",
       "52   This item worked great, but it broke after 6 m...  \n",
       "469  Maybe it's just their Vegetarian fare, but I'v...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_proba</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>No shifting, no bubbling, no peeling, not even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>#NAME?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>#NAME?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>I went to Bachi Burger on a friend's recommend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>I've had no trouble accessing the Internet, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>It plays louder than any other speaker of this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070223</td>\n",
       "      <td>They do not last forever, but is not overly ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076660</td>\n",
       "      <td>A standout scene.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094006</td>\n",
       "      <td>Cheap but hey it works.. Was pleasantly supris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099484</td>\n",
       "      <td>Seriously killer hot chai latte.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true  y_pred  y_pred_proba  \\\n",
       "108       1       0      0.001259   \n",
       "596       1       0      0.008474   \n",
       "560       1       0      0.008474   \n",
       "551       1       0      0.010288   \n",
       "146       1       0      0.029905   \n",
       "136       1       0      0.059850   \n",
       "181       1       0      0.070223   \n",
       "387       1       0      0.076660   \n",
       "104       1       0      0.094006   \n",
       "573       1       0      0.099484   \n",
       "\n",
       "                                                  text  \n",
       "108  No shifting, no bubbling, no peeling, not even...  \n",
       "596                                             #NAME?  \n",
       "560                                             #NAME?  \n",
       "551  I went to Bachi Burger on a friend's recommend...  \n",
       "146  I've had no trouble accessing the Internet, do...  \n",
       "136  It plays louder than any other speaker of this...  \n",
       "181  They do not last forever, but is not overly ex...  \n",
       "387                                A standout scene.    \n",
       "104  Cheap but hey it works.. Was pleasantly supris...  \n",
       "573                   Seriously killer hot chai latte.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction analysis on test data\n",
    "y_pred_proba = pipeline.predict_proba(x_test['text_pre'])\n",
    "y_true = y_test['positive']\n",
    "# create dataframe with true and predicted labels\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'y_pred_proba': y_pred_proba[:,1]})\n",
    "# add text to dataframe\n",
    "df['text'] = x_test['text']\n",
    "#select only false positives and ranked by probability\n",
    "false_positive_df = df[(df['y_true']==0) & (df['y_pred']==1)].sort_values('y_pred_proba', ascending=False)\n",
    "display(false_positive_df.head(10))\n",
    "\n",
    "#select only false negative and ranked by probability\n",
    "false_negative_df = df[(df['y_true']==1) & (df['y_pred']==0)].sort_values('y_pred_proba', ascending=True)\n",
    "display(false_negative_df.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No shifting, no bubbling, no peeling, not even a scratch, NOTHING!I couldn't be more happier with my new one for the Droid.\n",
      "#NAME?\n",
      "#NAME?\n",
      "I went to Bachi Burger on a friend's recommendation and was not disappointed.\n",
      "I've had no trouble accessing the Internet, downloading ringtones or performing any of the functions.\n",
      "It plays louder than any other speaker of this size; the price is so low that most would think the quality is lacking, however, it's not.\n",
      "They do not last forever, but is not overly expensive to replace.Easy to operate and the sound is much better than others I have tried.\n",
      "A standout scene.  \n",
      "Cheap but hey it works.. Was pleasantly suprised given the low cost of this item.\n",
      "Seriously killer hot chai latte.\n"
     ]
    }
   ],
   "source": [
    "_ = false_negative_df[\"text\"].iloc[:10].apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's this pandering to the audience that sabotages most of his films.  \n",
      "This movie now joins Revenge of the Boogeyman and Zombiez as part of the hellish trinity of horror films.  \n",
      "The only consistent thread holding the series together were the amazing performances of Leni Parker and Anita LaSelva as the two Taelons in quiet idealogical conflict.  \n",
      "It defeats the purpose of a bluetooth headset.\n",
      "The directing and the cinematography aren't quite as good.  \n",
      "The film is way too long.  \n",
      "It's AGGRAVATING!\n",
      "This movie suffered because of the writing, it needed more suspense.  \n",
      "This item worked great, but it broke after 6 months of use.\n",
      "Maybe it's just their Vegetarian fare, but I've been twice and I thought it was average at best.\n"
     ]
    }
   ],
   "source": [
    "_ = false_positive_df[\"text\"].iloc[:10].apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('metaltf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bb8f953e5a51e575a0614eea2cfd8668a4922a5c3f594783b10510e33be4fa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
